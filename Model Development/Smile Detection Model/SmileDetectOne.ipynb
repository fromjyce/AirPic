{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fWxPIrebLSak"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sACHdculLq_l",
        "outputId": "46367964-3da6-47aa-f5c2-7c52aef2d193"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DetectSmileModel:\n",
        "    def __init__(self, data_dir, img_size=(100, 100), batch_size=30):\n",
        "        self.initial_epochs = 10\n",
        "        self.data_dir = data_dir\n",
        "        self.img_size = img_size\n",
        "        self.batch_size = batch_size\n",
        "        self.history = None\n",
        "        self.test_dataset = None\n",
        "        self.validation_dataset = None\n",
        "        self.train_dataset = None\n",
        "        self.model = None\n",
        "        self.class_names = None\n",
        "\n",
        "    def preprocess_input(self, x):\n",
        "        return tf.keras.applications.vgg16.preprocess_input(x)\n",
        "\n",
        "    def build_model(self):\n",
        "        # Load the training dataset\n",
        "        self.train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "            self.data_dir,\n",
        "            validation_split=0.2,\n",
        "            subset=\"training\",\n",
        "            seed=123,\n",
        "            image_size=self.img_size,\n",
        "            batch_size=self.batch_size\n",
        "        )\n",
        "\n",
        "        self.class_names = self.train_dataset.class_names\n",
        "        print(self.class_names)\n",
        "\n",
        "        # Load the validation dataset\n",
        "        self.validation_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "            self.data_dir,\n",
        "            validation_split=0.2,\n",
        "            subset=\"validation\",\n",
        "            seed=123,\n",
        "            image_size=self.img_size,\n",
        "            batch_size=self.batch_size\n",
        "        )\n",
        "\n",
        "        # Create the test dataset\n",
        "        val_batches = tf.data.experimental.cardinality(self.validation_dataset)\n",
        "        self.test_dataset = self.validation_dataset.take(val_batches // 5)\n",
        "        validation_dataset = self.validation_dataset.skip(val_batches // 5)\n",
        "\n",
        "        # Improve performance using prefetching\n",
        "        AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "        self.train_dataset = self.train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "        self.validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "        self.test_dataset = self.test_dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "        # Load the base VGG16 model\n",
        "        base_model = tf.keras.applications.vgg16.VGG16(input_shape=self.img_size + (3,), include_top=False,\n",
        "                                                       weights=\"imagenet\")\n",
        "\n",
        "        # Unfreeze the base model layers\n",
        "        base_model.trainable = True\n",
        "\n",
        "        # Build the model architecture\n",
        "        inputs = tf.keras.Input(shape=self.img_size + (3,))\n",
        "        x = self.preprocess_input(inputs)\n",
        "        x = base_model(x, training=True)\n",
        "        x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "        x = tf.keras.layers.Dropout(0.2)(x)\n",
        "        outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "        self.model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "        self.model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "        self.model.summary()\n",
        "\n",
        "        # Evaluate the model on the validation dataset\n",
        "        loss0, accuracy0 = self.model.evaluate(validation_dataset)\n",
        "        print(\"Initial loss: {:.2f}\".format(loss0))\n",
        "        print(\"Initial accuracy: {:.2f}\".format(accuracy0))\n",
        "\n",
        "        # Train the model\n",
        "        self.history = self.model.fit(\n",
        "            self.train_dataset,\n",
        "            epochs=self.initial_epochs,\n",
        "            validation_data=validation_dataset,\n",
        "            validation_steps=len(validation_dataset),\n",
        "            steps_per_epoch=len(self.train_dataset),\n",
        "        )\n",
        "\n",
        "        # Enable fine-tuning\n",
        "        base_model.trainable = True\n",
        "\n",
        "        # Fine-tune from a specific layer onwards\n",
        "        fine_tune_at = 10\n",
        "\n",
        "        # Freeze layers before the fine-tuning layer\n",
        "        for layer in base_model.layers[:fine_tune_at]:\n",
        "            layer.trainable = False\n",
        "\n",
        "        # Recompile the model for fine-tuning\n",
        "        self.model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "                           optimizer='adam',\n",
        "                           metrics=['accuracy'])\n",
        "\n",
        "        self.model.summary()\n",
        "\n",
        "    def fine_tune(self, epochs):\n",
        "        total_epochs = self.initial_epochs + epochs\n",
        "\n",
        "        # Fine-tune the model\n",
        "        history_fine = self.model.fit(self.train_dataset,\n",
        "                                      epochs=total_epochs,\n",
        "                                      initial_epoch=self.history.epoch[-1],\n",
        "                                      validation_data=self.validation_dataset)\n",
        "        return history_fine\n",
        "\n",
        "\n",
        "    def report(self):\n",
        "        acc = self.history.history['accuracy']\n",
        "        val_acc = self.history.history['val_accuracy']\n",
        "\n",
        "        loss = self.history.history['loss']\n",
        "        val_loss = self.history.history['val_loss']\n",
        "\n",
        "        return acc, val_acc, loss, val_loss\n",
        "\n",
        "    def evaluate(self):\n",
        "        loss, accuracy = self.model.evaluate(self.test_dataset)\n",
        "        print('Test accuracy :', accuracy)\n",
        "\n",
        "    def save_model(self, save_path):\n",
        "        if self.model is not None:\n",
        "            self.model.save(save_path)\n",
        "            print(\"Model saved successfully.\")\n",
        "        else:\n",
        "            print(\"No model to save.\")\n",
        "\n",
        "    def load_model(self, model_path):\n",
        "        self.model = tf.keras.models.load_model(model_path)\n",
        "        print(\"Model loaded successfully.\")\n",
        "\n",
        "    def predict(self, image):\n",
        "        if self.model is not None:\n",
        "            image = tf.expand_dims(image, 0)\n",
        "            image = self.preprocess_input(image)\n",
        "            prediction = self.model.predict(image)[0][0]\n",
        "            if prediction < 0.5:\n",
        "                return \"No Smile\"\n",
        "            else:\n",
        "                return \"Smile\"\n",
        "        else:\n",
        "            print(\"No model loaded.\")\n",
        "\n",
        "    def prediction(self):\n",
        "        # Retrieve a batch of images from the test set\n",
        "        image_batch, label_batch = self.test_dataset.as_numpy_iterator().next()\n",
        "        predictions = self.model.predict_on_batch(image_batch).flatten()\n",
        "\n",
        "        # Apply a sigmoid since our model returns logits\n",
        "        predictions = tf.nn.sigmoid(predictions)\n",
        "        predictions = tf.where(predictions < 0.5, 0, 1)\n",
        "\n",
        "        print('Predictions:\\n', predictions.numpy())\n",
        "        print('Labels:\\n', label_batch)"
      ],
      "metadata": {
        "id": "rCHdcbUTL9xJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage:\n",
        "model = DetectSmileModel(data_dir='drive/MyDrive/ColabDrive/SmileDetection/')\n",
        "model.build_model()\n",
        "model.save_model('vgg_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_gX0qZuL_yf",
        "outputId": "28c77815-5d8e-4931-9cc3-a0d89435fcdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5891 files belonging to 2 classes.\n",
            "Using 4713 files for training.\n",
            "['not_smile', 'smile']\n",
            "Found 5891 files belonging to 2 classes.\n",
            "Using 1178 files for validation.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 2s 0us/step\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 100, 100, 3)]     0         \n",
            "                                                                 \n",
            " tf.__operators__.getitem (  (None, 100, 100, 3)       0         \n",
            " SlicingOpLambda)                                                \n",
            "                                                                 \n",
            " tf.nn.bias_add (TFOpLambda  (None, 100, 100, 3)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " vgg16 (Functional)          (None, 3, 3, 512)         14714688  \n",
            "                                                                 \n",
            " global_average_pooling2d (  (None, 512)               0         \n",
            " GlobalAveragePooling2D)                                         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14715201 (56.13 MB)\n",
            "Trainable params: 14715201 (56.13 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "32/32 [==============================] - 256s 4s/step - loss: 1.5845 - accuracy: 0.4659\n",
            "Initial loss: 1.58\n",
            "Initial accuracy: 0.47\n",
            "Epoch 1/10\n",
            "158/158 [==============================] - 862s 5s/step - loss: 0.9869 - accuracy: 0.5846 - val_loss: 0.6343 - val_accuracy: 0.6119\n",
            "Epoch 2/10\n",
            "158/158 [==============================] - 18s 112ms/step - loss: 0.6581 - accuracy: 0.6155 - val_loss: 0.5685 - val_accuracy: 0.5906\n",
            "Epoch 3/10\n",
            "158/158 [==============================] - 17s 109ms/step - loss: 0.5346 - accuracy: 0.7384 - val_loss: 0.3739 - val_accuracy: 0.8678\n",
            "Epoch 4/10\n",
            "158/158 [==============================] - 18s 111ms/step - loss: 0.3304 - accuracy: 0.8761 - val_loss: 0.3088 - val_accuracy: 0.8795\n",
            "Epoch 5/10\n",
            "158/158 [==============================] - 18s 111ms/step - loss: 0.4158 - accuracy: 0.8453 - val_loss: 0.3030 - val_accuracy: 0.8923\n",
            "Epoch 6/10\n",
            "158/158 [==============================] - 18s 111ms/step - loss: 0.2578 - accuracy: 0.9090 - val_loss: 0.2343 - val_accuracy: 0.9072\n",
            "Epoch 7/10\n",
            "158/158 [==============================] - 19s 118ms/step - loss: 0.2495 - accuracy: 0.9160 - val_loss: 0.2946 - val_accuracy: 0.8827\n",
            "Epoch 8/10\n",
            "158/158 [==============================] - 18s 111ms/step - loss: 0.2521 - accuracy: 0.9124 - val_loss: 0.2609 - val_accuracy: 0.9062\n",
            "Epoch 9/10\n",
            "158/158 [==============================] - 18s 113ms/step - loss: 0.2031 - accuracy: 0.9243 - val_loss: 0.2221 - val_accuracy: 0.9072\n",
            "Epoch 10/10\n",
            "158/158 [==============================] - 18s 110ms/step - loss: 0.1797 - accuracy: 0.9327 - val_loss: 0.2340 - val_accuracy: 0.9158\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 100, 100, 3)]     0         \n",
            "                                                                 \n",
            " tf.__operators__.getitem (  (None, 100, 100, 3)       0         \n",
            " SlicingOpLambda)                                                \n",
            "                                                                 \n",
            " tf.nn.bias_add (TFOpLambda  (None, 100, 100, 3)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " vgg16 (Functional)          (None, 3, 3, 512)         14714688  \n",
            "                                                                 \n",
            " global_average_pooling2d (  (None, 512)               0         \n",
            " GlobalAveragePooling2D)                                         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14715201 (56.13 MB)\n",
            "Trainable params: 12979713 (49.51 MB)\n",
            "Non-trainable params: 1735488 (6.62 MB)\n",
            "_________________________________________________________________\n",
            "Model saved successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3ZGT-QLLEew",
        "outputId": "eaa30889-6b0e-4c62-871f-fe00b71649fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:5820: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 3s 68ms/step - loss: 0.2671 - accuracy: 0.9125\n",
            "Test accuracy : 0.9125000238418579\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fine_tune(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1VPWFVqLIhS",
        "outputId": "a851a0cb-2312-4d9f-a499-b981184dbc3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/20\n",
            "158/158 [==============================] - 11s 68ms/step - loss: 0.1735 - accuracy: 0.9414 - val_loss: 0.2561 - val_accuracy: 0.9168\n",
            "Epoch 11/20\n",
            "158/158 [==============================] - 12s 74ms/step - loss: 0.1699 - accuracy: 0.9417 - val_loss: 0.2201 - val_accuracy: 0.9211\n",
            "Epoch 12/20\n",
            "158/158 [==============================] - 13s 79ms/step - loss: 0.1592 - accuracy: 0.9457 - val_loss: 0.2275 - val_accuracy: 0.9179\n",
            "Epoch 13/20\n",
            "158/158 [==============================] - 12s 75ms/step - loss: 0.1613 - accuracy: 0.9438 - val_loss: 0.2740 - val_accuracy: 0.9190\n",
            "Epoch 14/20\n",
            "158/158 [==============================] - 12s 72ms/step - loss: 0.1778 - accuracy: 0.9438 - val_loss: 0.3645 - val_accuracy: 0.9158\n",
            "Epoch 15/20\n",
            "158/158 [==============================] - 13s 79ms/step - loss: 0.1823 - accuracy: 0.9414 - val_loss: 0.2524 - val_accuracy: 0.9211\n",
            "Epoch 16/20\n",
            "158/158 [==============================] - 12s 74ms/step - loss: 0.1890 - accuracy: 0.9389 - val_loss: 0.2356 - val_accuracy: 0.9158\n",
            "Epoch 17/20\n",
            "158/158 [==============================] - 11s 67ms/step - loss: 0.1534 - accuracy: 0.9487 - val_loss: 0.2479 - val_accuracy: 0.9264\n",
            "Epoch 18/20\n",
            "158/158 [==============================] - 12s 72ms/step - loss: 0.1403 - accuracy: 0.9516 - val_loss: 0.2314 - val_accuracy: 0.9200\n",
            "Epoch 19/20\n",
            "158/158 [==============================] - 12s 72ms/step - loss: 0.1363 - accuracy: 0.9542 - val_loss: 0.1965 - val_accuracy: 0.9382\n",
            "Epoch 20/20\n",
            "158/158 [==============================] - 11s 71ms/step - loss: 0.1351 - accuracy: 0.9525 - val_loss: 0.2574 - val_accuracy: 0.9211\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a5a50f10100>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_model(\"vgg_model_ft_one.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ngCufAHLy9q",
        "outputId": "99c235c1-f303-4589-b40f-a0df91bdb99c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8_44-DbMQok",
        "outputId": "54af9020-05a4-44ae-ae1a-b5f74877006a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 1s 40ms/step - loss: 0.2951 - accuracy: 0.9292\n",
            "Test accuracy : 0.9291666746139526\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fine_tune(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owdxU0kKMZDL",
        "outputId": "f7868da1-c006-4d77-b908-c95f15d2ccf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/20\n",
            "158/158 [==============================] - 12s 74ms/step - loss: 0.1424 - accuracy: 0.9542 - val_loss: 0.2463 - val_accuracy: 0.9254\n",
            "Epoch 11/20\n",
            "158/158 [==============================] - 15s 94ms/step - loss: 0.1476 - accuracy: 0.9489 - val_loss: 0.2822 - val_accuracy: 0.9222\n",
            "Epoch 12/20\n",
            "158/158 [==============================] - 11s 67ms/step - loss: 0.1353 - accuracy: 0.9546 - val_loss: 0.2889 - val_accuracy: 0.9243\n",
            "Epoch 13/20\n",
            "158/158 [==============================] - 12s 73ms/step - loss: 0.1265 - accuracy: 0.9567 - val_loss: 0.2702 - val_accuracy: 0.9211\n",
            "Epoch 14/20\n",
            "158/158 [==============================] - 15s 91ms/step - loss: 0.1199 - accuracy: 0.9563 - val_loss: 0.2383 - val_accuracy: 0.9286\n",
            "Epoch 15/20\n",
            "158/158 [==============================] - 11s 69ms/step - loss: 0.1108 - accuracy: 0.9593 - val_loss: 0.3415 - val_accuracy: 0.9264\n",
            "Epoch 16/20\n",
            "158/158 [==============================] - 12s 77ms/step - loss: 0.1083 - accuracy: 0.9597 - val_loss: 0.2986 - val_accuracy: 0.9179\n",
            "Epoch 17/20\n",
            "158/158 [==============================] - 12s 75ms/step - loss: 0.1170 - accuracy: 0.9590 - val_loss: 0.3450 - val_accuracy: 0.9243\n",
            "Epoch 18/20\n",
            "158/158 [==============================] - 12s 71ms/step - loss: 0.1285 - accuracy: 0.9561 - val_loss: 0.3010 - val_accuracy: 0.9275\n",
            "Epoch 19/20\n",
            "158/158 [==============================] - 12s 75ms/step - loss: 0.1109 - accuracy: 0.9612 - val_loss: 0.2649 - val_accuracy: 0.9275\n",
            "Epoch 20/20\n",
            "158/158 [==============================] - 11s 71ms/step - loss: 0.0982 - accuracy: 0.9663 - val_loss: 0.3371 - val_accuracy: 0.9264\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a5a50414370>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_model(\"vgg_model_ft_two.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRpj57MiNOPu",
        "outputId": "d1c76c7e-9208-42ec-eb9c-fa234f692e0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ex7ivhH-NTeg",
        "outputId": "bdd56418-6156-46b8-9552-b057a1f28d85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 1s 40ms/step - loss: 0.3163 - accuracy: 0.9208\n",
            "Test accuracy : 0.9208333492279053\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fine_tune(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBI25JDfNYtf",
        "outputId": "c788b1c3-3cc4-4d5b-8d7f-8a9316538e91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/15\n",
            "158/158 [==============================] - 12s 72ms/step - loss: 0.1155 - accuracy: 0.9620 - val_loss: 0.3036 - val_accuracy: 0.9232\n",
            "Epoch 11/15\n",
            "158/158 [==============================] - 12s 70ms/step - loss: 0.0919 - accuracy: 0.9684 - val_loss: 0.3261 - val_accuracy: 0.9158\n",
            "Epoch 12/15\n",
            "158/158 [==============================] - 12s 73ms/step - loss: 0.0789 - accuracy: 0.9716 - val_loss: 0.3170 - val_accuracy: 0.9200\n",
            "Epoch 13/15\n",
            "158/158 [==============================] - 14s 84ms/step - loss: 0.0834 - accuracy: 0.9680 - val_loss: 0.2903 - val_accuracy: 0.9275\n",
            "Epoch 14/15\n",
            "158/158 [==============================] - 12s 72ms/step - loss: 0.0737 - accuracy: 0.9722 - val_loss: 0.3342 - val_accuracy: 0.9264\n",
            "Epoch 15/15\n",
            "158/158 [==============================] - 14s 84ms/step - loss: 0.0788 - accuracy: 0.9720 - val_loss: 0.3596 - val_accuracy: 0.9232\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a5a304e7d60>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_model(\"vgg_model_ft_three.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lhDSqAUOzZC",
        "outputId": "3ba0f14f-4be5-40aa-c328-0cb7d50b8f07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate()"
      ],
      "metadata": {
        "id": "yHu6caALO8SV",
        "outputId": "5cdebbe7-5daf-4b2a-88f9-c91c56c0e52b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 1s 59ms/step - loss: 0.4047 - accuracy: 0.9125\n",
            "Test accuracy : 0.9125000238418579\n"
          ]
        }
      ]
    }
  ]
}
